{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self,data=None):\n",
    "        self.data=data\n",
    "        self.df=data['ecog_data'][()]\n",
    "        print('df',self.df.shape)\n",
    "        self.bad_idx=np.zeros(self.df.shape[1],dtype='bool')\n",
    "        self.bad_chans=np.zeros(self.df.shape[0],dtype='bool')\n",
    "        \n",
    "    #what do I want to filter??\n",
    "    #first, detect channels that are just flat signal\n",
    "    def bad_chan(self,std_dev=True):\n",
    "        unique_entr_per_chan=np.count_nonzero(np.diff(np.sort(self.df)), axis=1)+1\n",
    "        #which channels have only few entries? Throw away\n",
    "        self.bad_chans=unique_entr_per_chan<10\n",
    "        #also, throw away channels with a STD that reallt deviates from rest (for now)\n",
    "        if(std_dev):\n",
    "            all_std=self.data['SD_channels'][()]\n",
    "            std_std=np.std(all_std)\n",
    "            std_mean=np.mean(all_std)\n",
    "            too_high_std=all_std>std_mean+1.5*std_std\n",
    "            self.bad_chans=np.logical_or(self.bad_chans,too_high_std)\n",
    "            \n",
    "    #second, get indices of intermediate flat signal\n",
    "    def flat_sig(self):\n",
    "        #all entries in a column the same?\n",
    "        equal=np.all(self.df == self.df[0,:], axis = 0)\n",
    "        self.bad_idx[equal]=True\n",
    "        #entries with high altitude? NOTE: THERE IS CURRENTLY AN ERROR IN THE CHANARTIFACT DATA THAT DOESN'T ACCOUNT FOR LOWER SAMPLING RATE\n",
    "        #here is a fix for the bug. remove later \n",
    "        self.bad_idx[np.array(self.data['allChanArtifactInds'][()][:],dtype=int)]=True\n",
    "        \n",
    "    def preprocess(self,by_std_dev=True,by_artifact=True):\n",
    "        self.flat_sig()\n",
    "        self.bad_chan(std_dev=by_std_dev)\n",
    "        return self.df, self.bad_chans,self.bad_idx\n",
    "        \n",
    "    \n",
    "#     #third, vals with too high of a variance are to be excluded. Note that varience is calculated without bad points\n",
    "#     #for excluding high vars, we calculate the variance of each channel, calc the std across these variances, exclude values \n",
    "#     #that are more than 2 std away\n",
    "#     def high_var(self):\n",
    "#         #next, let's look at variation changes per channel\n",
    "#         #get rid of points that are way off the mean\n",
    "#         vars_per_chan=[]\n",
    "#         for i in range(self.data.shape[0]):\n",
    "#             if self.bad_chans[i]!=True:\n",
    "#                 mean=np.mean(self.data[i,self.bad_idx[i]!=True])\n",
    "#                 std=np.std(self.data[i,self.bad_idx[i]!=True])\n",
    "#                 self.bad_idx[i]=np.logical_or(self.bad_idx[i],self.bad_idx[i]>mean+2*std)\n",
    "#                 vars_per_chan+=[std**2]\n",
    "#             else:\n",
    "#                 vars_per_chan+=[np.nan]\n",
    "#         #calc variance across time points that are OK\n",
    "#         var=np.array(vars_per_chan)\n",
    "#         #what is standart deviation and mean among the variances OF GOOD CHANNELS?\n",
    "#         varmean=np.nanmean(var[self.bad_chans!=True])\n",
    "#         varstd=np.std(var[self.bad_chans!=True])\n",
    "#         print(varmean,varstd)\n",
    "#         #get rid of avg that shoot way above. THESE ARE CHANNELS\n",
    "#         self.bad_var=var>varmean+1*varstd\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('df', (98, 43200500))\n"
     ]
    }
   ],
   "source": [
    "# df=h5py.File('/data2/users/stepeter/Preprocessing/Reref/processed_a0f66459_5.h5')\n",
    "# pr=Preprocessor(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('new bad idx', (43200500,))\n",
      "('new bad chans', (98,))\n",
      "('and then', (98,))\n"
     ]
    }
   ],
   "source": [
    "# dat,tt,tw=pr.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98,)\n",
      "(43200500,)\n",
      "(94, 43200500)\n",
      "[ True]\n"
     ]
    }
   ],
   "source": [
    "# print(tt.shape)\n",
    "# print(tw.shape)\n",
    "# aight=dat[tt!=True]\n",
    "# print(aight.shape)\n",
    "# print(tw[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepr.bad_var.shape#print(np.unique(prepr.bad_idx,coun))\n",
    "\n",
    "# print(prepr.data[0].shape)\n",
    "# print(prepr.bad_idx.shape)\n",
    "# for p in range(0,127):\n",
    "#     if not prepr.bad_chans[p]: \n",
    "#         if not prepr.bad_var[p]:\n",
    "#             plt.plot(prepr.data[p,prepr.bad_idx[p]!=True])\n",
    "#     #mark bad points\n",
    "#     #plt.plot(np.arange(len(prepr.bad_idx[p]))[prepr.bad_idx[p]],np.zeros(len(prepr.bad_idx[p]))[prepr.bad_idx[p]]-.02, \"-\", markersize=1,)\n",
    "# plt.legend()\n",
    "\n",
    "# for p in range(0,127):\n",
    "#     if (bad_chans)\n",
    "#     plt.plot(prepr.data[p])\n",
    "\n",
    "# plt.plot(tt[0])\n",
    "# plt.plot(tt[1])\n",
    "# plt.plot(peaks, tt[1][peaks], \"x\")\n",
    "\n",
    "\n",
    "# np.random.seed(33)\n",
    "# test=np.random.uniform(0.9,1,(1,100))\n",
    "# print(test.shape)\n",
    "# test[0,10:20]=0\n",
    "# #test[1,15:25]=0\n",
    "# test[0,40:73]=0.95\n",
    "# #test[1,15:25]=0.95\n",
    "# #peaks=argrelextrema(test,np.less,order=25)\n",
    "# #plt.vlines(peaks,ymin=0, ymax=1)\n",
    "# #print(peaks)\n",
    "# grads=(np.gradient(test,axis=1)==0)\n",
    "# print(np.zeros(len(grads[p]))[grads[p]].shape)\n",
    "# for p in range(test.shape[0]):\n",
    "#     plt.plot(test[p])\n",
    "#     ym1 = np.ma.masked_where(grads[p] ==False , grads[p])\n",
    "#     plt.plot(np.arange(len(grads[p])),ym1-1.02, \"-\")\n",
    "\n",
    "# #np.argwhere(grads[1])[0]\n",
    "# #print(grads)\n",
    "# np.apply_along_axis(np.argwhere,1,grads)\n",
    "# np.argwhere(grads[2])\n",
    "# np.apply_along_axis(np.unique,1,grads)\n",
    "\n",
    "\n",
    "# ee=np.eye(3)\n",
    "# mask=np.zeros(ee.shape[0],dtype='bool')\n",
    "# mask[1]=True\n",
    "# mask[0]=True\n",
    "# #print(mask)\n",
    "\n",
    "# test=np.zeros(5)\n",
    "# np.logical_or(np.ones(5),test==1)\n",
    "\n",
    "\n",
    "# A=np.arange(5)\n",
    "# A[np.arange(2,3)]=False\n",
    "# print(A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
