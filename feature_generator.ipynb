{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.fftpack import fft, fftfreq\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import pyplot\n",
    "import h5py\n",
    "from simple_edf_preprocessing import Preprocessor\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a ECOG PCA class for its PCA object, hyperparas and other stuff\n",
    "class PCA_Ecog_preprocessed:\n",
    "    def __init__(self,path=None,pca_obj=None,wsize=30):\n",
    "        self.pca=pca_obj\n",
    "        #hyperpara in s for how large the time window should be on whihc we calculate our fourier trafo\n",
    "        self.wsize=wsize\n",
    "        #sampling frequency and last sample taken\n",
    "        if(path != None):\n",
    "            self.df=h5py.File(path)\n",
    "            #preprocess data\n",
    "            self.Preprocessor=Preprocessor(self.df)\n",
    "            self.data,self.bad_chan,self.bad_idx=self.Preprocessor.preprocess()\n",
    "            self.data=self.data[self.bad_chan!=True]\n",
    "            self.sfreq=int(self.df['f_sample'][()])\n",
    "            #how many samples in this dataset?\n",
    "            self.end=self.data.shape[1]-1\n",
    "            self.bin_data()\n",
    "            \n",
    "        else:\n",
    "            self.df=None\n",
    "            self.sfreq=None\n",
    "            self.end=None\n",
    "    \n",
    "    #this function restructures the data into a 3D structure, where each row presents a channel, each column one second\n",
    "    #and the depth is the amount of samples per seconds (sfreq). \n",
    "    #This is to discard seconds where bad_idx are present and to be on par with the labels in the end\n",
    "    #This function also creates a mask of bins to discard from the bad_idx array\n",
    "    def bin_data(self):\n",
    "        #where to end?\n",
    "        end=self.end//self.sfreq\n",
    "        self.data_bin=self.data[:,:end*self.sfreq].reshape(self.data.shape[0],end,self.sfreq)\n",
    "        self.mask_bin=np.all(self.bad_idx[:end*self.sfreq].reshape(end,self.sfreq),axis=1)\n",
    "\n",
    "        \n",
    "      \n",
    "    def standardize(self, data,ax=0):\n",
    "        self.data_mean=np.mean(data,axis=ax)\n",
    "        data_dem=data-self.data_mean\n",
    "        std=np.std(data,axis=ax)\n",
    "        data_stand=data_dem/std\n",
    "        #self.data_scal=1000000\n",
    "        #data_scal=self.data_scal*data_dem\n",
    "        #return data_scal\n",
    "        return data_stand\n",
    "    \n",
    "#this function caps at 200Hz, then bins the data in a logarithmic fashion to account for smaller psd values in higher freqs\n",
    "    def bin_psd(self,fr,psd):\n",
    "        fr_trun=fr[fr<=200]\n",
    "        fr_total=len(fr_trun)\n",
    "        fr_bins=np.arange(int(np.log2(fr_total)+1))\n",
    "        #truncate everythin above 200Hz\n",
    "        psd=psd[:,fr<=200]\n",
    "        psd_bins=np.zeros((psd.shape[0],len(fr_bins)))\n",
    "        prev=0\n",
    "        max_psd_per_bin=np.exp2(fr_bins).astype('int')\n",
    "        prev=0\n",
    "        for b in fr_bins:\n",
    "            if (b==len(fr_bins) or max_psd_per_bin[b]>=psd.shape[1]):\n",
    "                psd_bins[:,b]+=np.sum(psd[:,prev:],axis=1)\n",
    "            else:\n",
    "                psd_bins[:,b]=np.sum(psd[:,prev:max_psd_per_bin[b]],axis=1)\n",
    "            prev=max_psd_per_bin[b]\n",
    "        return fr_bins, psd_bins\n",
    "\n",
    "    \n",
    "        \n",
    "    #create matrix as follows:\n",
    "    #columns: channels, for each channel the 200 frequencies (0-200Hz) (hece freq*cha length) BUT BINNED logarithmically\n",
    "    #rows: Time steps\n",
    "    #resulting matrix is 2D, Time Stepsx(Freq*Channels)\n",
    "    #note that this matrix is prone to constant change. Save the current data as member variable\n",
    "    def data_in_range(self,time_sta,time_stp):\n",
    "        if(self.df==None):\n",
    "            raise ValueError('Raw Data not set.')\n",
    "        time_it=time_sta\n",
    "        while True:\n",
    "            stop=time_it+self.wsize\n",
    "            if stop>=self.data_bin.shape[1]-1:\n",
    "                print('Not enough data for set end %d. Returning all data that is available in given range.'% time_stp)\n",
    "                break\n",
    "            #Note that each column is exactly one second.\n",
    "            #get data in range of ALL channels, applying the mask\n",
    "            curr_data=self.data_bin[:,range(time_it,stop)[self.mask_bin[start:stop]],:].reshape(self.data[0],-1)\n",
    "            #is this thing empty? continue\n",
    "            if not curr_data.size:\n",
    "                continue\n",
    "            #welch method \n",
    "            fr,psd=signal.welch(curr_data,self.sfreq)\n",
    "            fr_bin,psd_bin=self.bin_psd(fr,psd)\n",
    "            if time_it==time_sta:\n",
    "                self.fr_bin=fr_bin\n",
    "                #first time. create first column, flatten w/o argument is row major \n",
    "                mat=psd_bin.flatten()\n",
    "            else:\n",
    "                #after, add column for each time step\n",
    "                mat=np.column_stack((mat,psd_bin.flatten()))\n",
    "            time_it+=self.wsize\n",
    "            if time_it+self.wsize >= time_stp:\n",
    "                break\n",
    "        data_scal=self.standardize(mat.T)\n",
    "        self.curr_data=data_scal\n",
    "        return data_scal\n",
    "    \n",
    "    def vis_raw_data(self, start, stop, chans=None):\n",
    "        if(self.df==None):\n",
    "            raise ValueError('Raw Data not set (yet)')\n",
    "        if chans is None:\n",
    "            chans=range(self.data.shape[0])\n",
    "        st=int(start*self.sfreq)\n",
    "        stp=int(stop*self.sfreq)\n",
    "        data=self.data[:,st:stp]\n",
    "        for p in range(0,len(chans)-1):\n",
    "            plt.plot(data[p])\n",
    "        plt.show()\n",
    "    \n",
    "    def vis_welch_data(self,start,stop,no_chan=None):\n",
    "        #account for wsize\n",
    "        start=int(start/self.wsize)\n",
    "        stop=int(stop/self.wsize)\n",
    "        rem=self.curr_data[:,start:stop]\n",
    "        plt.imshow(np.log(rem),cmap='viridis',aspect='auto')\n",
    "        print(rem[4000,:])\n",
    "        \n",
    "    def vis_pc(self):\n",
    "        if self.PCA is None:\n",
    "            raise ValueError('PCA not set up yet. Please call setup_PCA first.')\n",
    "        for p in range(self.PCA.n_components):\n",
    "            plt.plot(self.PCA.transform(wut)[:,p])\n",
    "        plt.xlabel('Time (in w_size)')\n",
    "        plt.ylabel('PC Value')\n",
    "        plt.title('First %d principal components' % self.PCA.n_components)\n",
    "        plt.show()\n",
    "\n",
    "    #get elbow curve. This also outputs the optimal n_components for the given desired explained variancce.\n",
    "    def __elbow_curve(self,datapart,expl_var_lim):\n",
    "        components = range(1, datapart.shape[1] + 1)\n",
    "        explained_variance = []\n",
    "        #till where?\n",
    "        lim=min(50, datapart.shape[1])\n",
    "        count=0\n",
    "        for component in tqdm(components[:lim]):\n",
    "            pca = PCA(n_components=component)\n",
    "            pca.fit(datapart)\n",
    "            expl_var=sum(pca.explained_variance_ratio_)\n",
    "            explained_variance.append(expl_var)\n",
    "            count+=1\n",
    "            if(expl_var>(expl_var_lim/100.)):\n",
    "                optimal_no_comps=count\n",
    "                break\n",
    "        if(explained_variance[-1:][0]<(expl_var_lim/100.)):\n",
    "            print('Could not explain more than %3f percent of the variance. n_comps is therefore equal to the input dimension. Consider increasing data range or lowering demanded explained variance' % expl_var)\n",
    "            optimal_no_comps=datapart.shape[1]\n",
    "        sns_plot = sns.regplot(\n",
    "            x=np.array(components[:count]), y=explained_variance,\n",
    "            fit_reg=False).get_figure()\n",
    "        return optimal_no_comps\n",
    "    \n",
    "    def setup_PCA(self,expl_variance):\n",
    "        print('Setting up PCA on current data range...')\n",
    "        if self.curr_data is None:\n",
    "            raise ValueError('Data matrix not set yet. Please call data_in_range Func first.')\n",
    "        no_comps=self.__elbow_curve(self.curr_data,expl_variance)\n",
    "        self.pca=PCA(n_components=no_comps)\n",
    "        self.pca.fit(self.curr_data)\n",
    "        self.princ_components=self.pca.transform(self.curr_data)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('df', (97, 43200500))\n"
     ]
    }
   ],
   "source": [
    "pecog=PCA_Ecog_preprocessed('/data2/users/stepeter/Preprocessing/Reref/processed_cb46fd46_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /data1/ecog_project/ajile_data_release/cb46fd46_day_4.edf...\n",
      "EDF file detected\n",
      "EDF annotations detected (consider using raw.find_edf_events() to extract them)\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 86400999  =      0.000 ... 86400.999 secs...\n"
     ]
    }
   ],
   "source": [
    "mnestuff=mne.io.read_raw_edf('/data1/ecog_project/ajile_data_release/cb46fd46_day_4.edf',eog=[4],preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Info | 17 non-empty fields\n",
       "    bads : list | 0 items\n",
       "    buffer_size_sec : float | 1.0\n",
       "    ch_names : list | GRID1, GRID2, GRID3, GRID4, GRID5, GRID6, GRID7, GRID8, ...\n",
       "    chs : list | 98 items (EEG: 96, STIM: 1, EOG: 1)\n",
       "    comps : list | 0 items\n",
       "    custom_ref_applied : bool | False\n",
       "    dev_head_t : Transform | 3 items\n",
       "    events : list | 0 items\n",
       "    highpass : float | 0.0 Hz\n",
       "    hpi_meas : list | 0 items\n",
       "    hpi_results : list | 0 items\n",
       "    lowpass : float | 500.0 Hz\n",
       "    meas_date : int | 1427987220\n",
       "    nchan : int | 98\n",
       "    proc_history : list | 0 items\n",
       "    projs : list | 0 items\n",
       "    sfreq : float | 1000.0 Hz\n",
       "    acq_pars : NoneType\n",
       "    acq_stim : NoneType\n",
       "    ctf_head_t : NoneType\n",
       "    description : NoneType\n",
       "    dev_ctf_t : NoneType\n",
       "    dig : NoneType\n",
       "    experimenter : NoneType\n",
       "    file_id : NoneType\n",
       "    gantry_angle : NoneType\n",
       "    hpi_subsystem : NoneType\n",
       "    kit_system_id : NoneType\n",
       "    line_freq : NoneType\n",
       "    meas_id : NoneType\n",
       "    proj_id : NoneType\n",
       "    proj_name : NoneType\n",
       "    subject_info : NoneType\n",
       "    xplotter_layout : NoneType\n",
       ">"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnestuff.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-923470a2af1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpecog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_in_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-dc02ba5691f5>\u001b[0m in \u001b[0;36mdata_in_range\u001b[0;34m(self, time_sta, time_stp)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;31m#Note that each column is exactly one second.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;31m#get data in range of ALL channels, applying the mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mcurr_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_bin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_it\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_bin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0;31m#is this thing empty? continue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcurr_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'start' is not defined"
     ]
    }
   ],
   "source": [
    "wut=pecog.data_in_range(0,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pecog.setup_PCA(94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pecog.pca.fit(wut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr=pecog.pca.transform(pecog.curr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.81157505, -14.71728662,  -2.34965355, ...,   1.65272278,\n",
       "         -1.98378791,  -1.03052725],\n",
       "       [ -3.62768328, -16.40192335,  -2.04784517, ...,   2.41212364,\n",
       "         -2.19696157,  -0.27153308],\n",
       "       [-13.58255533,   3.27350952,   3.77294152, ...,   1.80580357,\n",
       "         -0.62542247,   1.32854282],\n",
       "       ..., \n",
       "       [  9.21359824,   0.9008957 ,   3.80799144, ...,  -0.08426016,\n",
       "         -0.97584345,   1.37733634],\n",
       "       [  8.33452942,   1.90464146,  -5.3162557 , ...,  -1.14187604,\n",
       "          1.20489029,  -0.85552777],\n",
       "       [ 11.08960914,   7.44386117,  -3.32637685, ...,  -0.93442396,\n",
       "         -0.95458346,   0.13851337]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pecog.PCA=PCA(n_components=com)\n",
    "pecog.PCA.fit(wut)\n",
    "pecog.PCA.n_components\n",
    "pecog.PCA.transform(wut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(pecog.PCA.n_components):\n",
    "    plt.plot(pecog.PCA.transform(wut)[:,p])\n",
    "plt.xlabel('Time (in w_size)')\n",
    "plt.ylabel('PC Value')\n",
    "plt.title('First %d principal components' % pecog.PCA.n_components)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pecog.vis_raw_data(0,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_trafo[:,0],data_trafo[:,1])\n",
    "print(data_trafo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin the frequencies logarithmitically (higher frequencies are much lpwer -> bin them together)\n",
    "#standardize (mean and unit variance feature\n",
    "#go up to 150Hz\n",
    "#since we bin emotions as well, do a) regression on percentage, b) classification at cutoff\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what are the outstsanding points here?\n",
    "time_idx=np.argwhere(data_trafo>2)[:,0]\n",
    "#what is happening at these points?\n",
    "#calculate back the time window:\n",
    "idx=time_idx*pecog.wsize\n",
    "print(idx)\n",
    "#calculate from time windows to sampling points\n",
    "start, stop = pecog.raw.time_as_index([idx[0]-5,idx[1]+5])\n",
    "inter=pecog.raw.get_data(picks=range(0,40), start=start, stop=stop,reject_by_annotation=None, return_times=False)\n",
    "print(inter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pecog.curr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pecog.vis_raw_data(idx[0]-5,idx[1]+5)\n",
    "pecog.vis_raw_data(0,idx[1]+400)\n",
    "pecog.vis_welch_data(50,time_idx[1]+200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_data=pecog.calc_data_mat(idx[1]+100,idx[1]+400)\n",
    "pecog.pca.fit(good_data)\n",
    "good_data_trafo=pecog.pca.transform(good_data)\n",
    "print(good_data_trafo.shape)\n",
    "print(good_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(good_data.shape)\n",
    "print(good_data_trafo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comps=pecog.pca.components_\n",
    "print(pecog.raw.info['ch_names'][28])\n",
    "print(comps.shape)\n",
    "comps=comps.reshape((127,-1,2))\n",
    "print(np.argmax(comps[:,:,1],axis=1))\n",
    "#plt.plot(comps[5:,5:,0].T)\n",
    "plt.plot(comps[:,:,1].T)\n",
    "plt.ylim(-0.005,0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pecog.raw.info['chs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data_trafo)\n",
    "plt.plot(good_data_trafo[:,0])\n",
    "plt.plot(good_data_trafo[:,1])\n",
    "#plt.xlim(-0.00001,0.00001)\n",
    "#plt.ylim(-0.00001,0.00001)\n",
    "\n",
    "#max(data_trafo[:,1])-min(data_trafo[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TEST STUFF\n",
    "###functions for first insight. delete later\n",
    "start, stop = pecog.raw.time_as_index([0, 51+pecog.wsize])\n",
    "print(stop-start)\n",
    "channel=pecog.raw.get_data(picks=[4,5],start=start, stop=stop,reject_by_annotation=None, return_times=False)\n",
    "#data=np.squeeze(channel[0])\n",
    "\n",
    "# Get real amplitudes of FFT (only in postive frequencies)\n",
    "fft_vals = np.absolute(np.fft.rfft(channel))\n",
    "# Get frequencies for amplitudes in Hz\n",
    "fft_freq = np.fft.rfftfreq(len(channel[0,:]), 1.0/pecog.sfreq)\n",
    "#welch method\n",
    "fr,psd=signal.welch(channel,pecog.sfreq)\n",
    "\n",
    "#throw away everything above 100Hz for now (and 0)\n",
    "freqs=fft_freq[fft_freq<101][1:]\n",
    "vals=fft_vals[:,fft_freq<101][:,1:]\n",
    "\n",
    "\n",
    "plt.plot(fr,psd[0])\n",
    "plt.plot(fr,psd[1])\n",
    "\n",
    "#plt.plot(freqs,vals[1])\n",
    "#plt.plot(freqs,vals[0])\n",
    "\n",
    "#plt.plot(fft_freq[1:], fft_vals[1:])\n",
    "#plt.xlabel('Frequency')\n",
    "#plt.ylabel('Intensity')\n",
    "#plt.show()\n",
    "#plt.plot(freqs,vals)\n",
    "#plt.xlabel('Frequency')\n",
    "#plt.ylabel('Intensity')\n",
    "\n",
    "#for 3D\n",
    "# fig = pyplot.figure()\n",
    "# ax = Axes3D(fig)\n",
    "\n",
    "# ax.scatter(data_trafo[:,0],data_trafo[:,1],data_trafo[:,2],c='b')\n",
    "# pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
