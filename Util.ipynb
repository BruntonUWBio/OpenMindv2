{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from Evals import get_f1, get_precision_recall, get_f1_from_pr\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, fbeta_score, roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationUtils:\n",
    "    def get_optimal_threshold(classifier,cv,x,y, go_after_pr = False): #are we optimizing for f1? or tpr-fpr?\n",
    "        optimal_threshs = []\n",
    "        for train, test in cv.split(x, y):\n",
    "            classifier.fit(x[train], y[train])\n",
    "            probas_ = classifier.predict_proba(x[test])\n",
    "            # Compute ROC curve\n",
    "            #this returns different tpr/fpr for different decision thresholds\n",
    "            if go_after_pr:\n",
    "                pre, rec, thresholds = precision_recall_curve(y[test],probas_[:,1])\n",
    "                f1 = get_f1_from_pr(pre,rec)\n",
    "                optimal_idx = np.argmax(f1)\n",
    "            else:\n",
    "                fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "                optimal_idx = np.argmax(tpr - fpr)\n",
    "            optimal_threshold = thresholds[optimal_idx]\n",
    "            optimal_threshs.append(optimal_threshold)\n",
    "\n",
    "        #now that we have this, what was the median best threshold?\n",
    "        return np.median(optimal_threshs)\n",
    "    \n",
    "    def get_auc_score(classifier,cv,x,y, go_after_pr = False): #are we optimizing for f1? or tpr-fpr?\n",
    "        aucs = []\n",
    "        for train, test in cv.split(x, y):\n",
    "            classifier.fit(x[train], y[train])\n",
    "            probas_ = classifier.predict_proba(x[test])\n",
    "            # Compute ROC curve\n",
    "            #this returns different tpr/fpr for different decision thresholds\n",
    "            if go_after_pr:\n",
    "                aucs.append(average_precision_score(y[test],probas_[:,1]))\n",
    "            else:\n",
    "                aucs.append(roc_auc_score(y[test],probas_[:,1]))\n",
    "                \n",
    "        #now that we have this, what was the median best threshold?\n",
    "        return np.mean(aucs)\n",
    "\n",
    "    def get_prediction(classifier,x,thresh):\n",
    "        y_pred = (classifier.predict_proba(x)[:,1]>thresh).astype(bool)\n",
    "        return y_pred\n",
    "    \n",
    "    def fit_predict(classifier, thresh, x,y,x_ev=None,y_ev=None):\n",
    "        classifier.fit(x, y) # fit the classifier\n",
    "        y_pred = ClassificationUtils.get_prediction(classifier,x,thresh) # predict on whole train set\n",
    "        if x_ev is None:\n",
    "            y_pred_ev = None\n",
    "        else:\n",
    "            y_pred_ev = ClassificationUtils.get_prediction(classifier,x_ev,thresh) #same for ev set\n",
    "        return y_pred, y_pred_ev\n",
    "    \n",
    "    def get_best_hyperparas_results(df):\n",
    "        pos = df['F1 Score Tr'].idxmax()\n",
    "        best_row=df.loc[pos] # get the row with highest ev score\n",
    "        return best_row       \n",
    "    \n",
    "    def fit_predict_eval_fill(df,idx,classifier,cv,x,y,x_ev,y_ev):\n",
    "        thresh = ClassificationUtils.get_optimal_threshold(classifier, cv, x, y) # get threshold using cv\n",
    "        y_pred,y_pred_ev = ClassificationUtils.fit_predict(classifier, x, y, x_ev, y_ev, thresh) # using that threshold, get predictions and f1 score\n",
    "        f1_tr=get_f1(y_pred,y) # calculate f1 scores for prediction on train set\n",
    "        f1_ev=get_f1(y_pred_ev,y_ev)\n",
    "        prec_tr,recall_tr = get_precision_recall(y_pred,y)\n",
    "        prec_ev,recall_ev = get_precision_recall(y_pred_ev,y_ev)\n",
    "        results_df.loc[idx] = [c,g,thresh,f1_tr,prec_tr,recall_tr,f1_ev,prec_ev,recall_ev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataUtils:\n",
    "    def get_data_from_file(wsize=100,sliding=10,s_sample=0,e_sample=12500, s_sample_ev=9000, e_sample_ev=12000, cutoff=None):\n",
    "        link='./data/ws_'+str(wsize)+'_str_'+str(sliding)+'_tr'+'_s_'+str(s_sample)+'_e_'+str(e_sample)+'_ev_'+'s_'+str(s_sample_ev)+'_e_'+str(e_sample_ev)+'_cut_'+str(cutoff)+'.hdf'\n",
    "        df = pd.read_hdf(link)\n",
    "        x = df['x'][0]\n",
    "        y = df['y'][0]\n",
    "        x_ev = df['x_ev'][0]\n",
    "        y_ev = df['y_ev'][0]\n",
    "    \n",
    "        return x,y,x_ev,y_ev\n",
    "\n",
    "    def save_data_to_file(x,y,x_ev,y_ev,wsize=100,sliding=10,s_sample=0,e_sample=12500, s_sample_ev=9000, e_sample_ev=12000,cutoff =None):\n",
    "        link='./data/ws_'+str(wsize)+'_str_'+str(sliding)+'_tr'+'_s_'+str(s_sample)+'_e_'+str(e_sample)+'_ev_'+'s_'+str(s_sample_ev)+'_e_'+str(e_sample_ev)+'_cut_'+str(cutoff)+'.hdf'\n",
    "        #save stuff to file:\n",
    "        df = pd.DataFrame(data=[[x,y,x_ev,y_ev]],columns=['x','y','x_ev','y_ev'])\n",
    "\n",
    "        df.to_hdf(link,key='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureUtils:\n",
    "    def standardize(data,ax=0):\n",
    "        data_mean = np.mean(data,axis=ax)\n",
    "        data_dem = data-data_mean\n",
    "        std = np.std(data,axis=ax)\n",
    "        data_stand = data_dem/std\n",
    "        return data_stand\n",
    "\n",
    "    #this function caps at 150Hz, then bins the data in a logarithmic fashion to account for smaller psd values in higher freqs\n",
    "    def bin_psd(fr,psd):\n",
    "        fr_trun=fr[fr<=150]\n",
    "        fr_total=len(fr_trun)\n",
    "        fr_bins=np.arange(int(np.log2(max(fr_trun))+1))\n",
    "        #truncate everythin above 150Hz\n",
    "        psd=psd[:,fr<=150]\n",
    "        psd_bins=np.zeros((psd.shape[0],len(fr_bins)))\n",
    "        prev=0\n",
    "        #these are the general upper limits. they don't give info where in fr/psd these frequencies acutally are!\n",
    "        max_psd_per_bin=np.exp2(fr_bins).astype('int')\n",
    "        #hence we need this method:\n",
    "        prev=0\n",
    "        limits=np.zeros((max_psd_per_bin.shape[0],2),dtype='int')\n",
    "        for en,b in enumerate(max_psd_per_bin):\n",
    "            if en==0:\n",
    "                arr=np.where((fr_trun >=prev)&(fr_trun<=b))[0]\n",
    "            else:\n",
    "                arr=np.where((fr_trun >prev)&(fr_trun<=b))[0]\n",
    "            check=np.array([min(arr),max(arr)])\n",
    "            limits[np.log2(b).astype('int')]=check\n",
    "            prev=b\n",
    "        prev=0\n",
    "        for b in fr_bins:\n",
    "            if (b==fr_bins[-1] or limits[b][1]>=fr_total):\n",
    "                psd_bins[:,b]+=np.sum(psd[:,limits[b,0]:],axis=1)\n",
    "            else:\n",
    "                psd_bins[:,b]=np.sum(psd[:,limits[b,0]:limits[b,1]+1],axis=1)\n",
    "        return fr_bins, psd_bins\n",
    "\n",
    "\n",
    "    def get_no_comps(data,expl_var_lim):\n",
    "        comps=min(100,min(data.shape))\n",
    "        pca=PCA(n_components=comps)\n",
    "        pca.fit(data)\n",
    "        tot=0\n",
    "        for idx,c in enumerate(pca.explained_variance_ratio_):\n",
    "            tot+=c\n",
    "            if tot*100>expl_var_lim:\n",
    "                return idx+1\n",
    "        return pca.n_components_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P3 emocog",
   "language": "python",
   "name": "emocog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
